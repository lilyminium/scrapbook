#!/usr/bin/env python

import pathlib
import json
import glob
import os
import argparse
import tqdm

import pandas as pd
import numpy as np
import qcelemental as qcel
from rdkit import Chem
from numpy.testing import assert_equal

from openff.toolkit.typing.engines.smirnoff import ForceField
from openff.evaluator.backends import ComputeResources
from openff.evaluator.backends.dask import DaskLocalCluster
from openff.toolkit.topology.molecule import Molecule, unit
from openff.evaluator.workflow import Workflow


from utils import property_from_csv, dataset_from_csv

METHODS = {
    "hf": {"method": "hf", "basis": "6-31g*"},
    "default": {"method": "b3lyp-d3bj", "basis": "dzvp"},
    "resp2": {"method": "PW6B95", "basis": "cc-pV(D+d)Z"},
}

METHOD_FULL = {
    k: METHODS[k]["method"] + "/" + METHODS[k]["basis"]
    for k in METHODS
}

parser = argparse.ArgumentParser("Evaluate properties")
parser.add_argument("--delta", default=None, type=float)
parser.add_argument("--port", default=8004, type=int)
parser.add_argument("--method", default="resp2", type=str)

def write_training_set(propdir, training_set):
    dataset = dataset_from_csv("01_mnsol_data.csv")
    new_dataset = type(dataset)()
    for prop in dataset:
        if all(comp.smiles in training_set for comp in prop.substance):
            new_dataset.add_properties(prop)

    print(f"FOUND {len(new_dataset.properties)} PROPERTIES")
    
    trainfile = str(propdir / "training-set.json")
    new_dataset.json(trainfile)
    print(f"Wrote {trainfile}")


def write_options(propdir, port=8005):
    OPTIONS = """\
{
    "connection_options": {
        "server_address": "localhost",
        "server_port": """ + str(port) + """
    },
    "data_set_path": "training-set.json",
    "denominators": {
        "SolvationFreeEnergy": {
            "@type": "openff.evaluator.unit.Quantity",
            "unit": "kJ / mol",
            "value": 1
        }
    },
    "estimation_options": {
        "batch_mode": {
            "@type": "openff.evaluator.client.client.BatchMode",
            "value": "SharedComponents"
        },
        "calculation_layers": [
            "SimulationLayer"
        ]
    },
    "polling_interval": 600,
    "weights": {
        "SolvationFreeEnergy": 1.0
    }
}
    """
    optfile = str(propdir / "options.json")
    with open(optfile, "w") as f:
        f.write(OPTIONS)
    print(f"Wrote {optfile}")

def write_opt_in(outdir):
    OPTIN = """\
# ForceBalance input file generated by MakeInputFile.py
# The octothorpe '#' is a comment symbol
# Note: If the specified value is 'None' then the option will truly be set to None - not the string 'None'
# Note: 'Section' option types are more complicated and may require you to read the documentation
# Note: Boolean option types require no value, the key being present implies 'True'

$options
# (string) Directory containing force fields, relative to project directory
ffdir forcefield

# (string) Type of the penalty, L2 or L1 in the optimizer
penalty_type L2

# (allcap) The job type, defaults to a single-point evaluation of objective function
jobtype optimize

# (list) The names of force fields, corresponding to directory forcefields/file_name.(itp|gen)
forcefield force-field.offxml

# (int) Maximum number of steps in an optimization
maxstep 15

# (float) Convergence criterion of step size (just needs to fall below this threshold)
convergence_step 0.0001

# (float) Convergence criterion of objective function (in MainOptimizer this is the stdev of x2 over 10 steps)
convergence_objective 0.0001

# (float) Convergence criterion of gradient norm
convergence_gradient 0.0001

# The number of convergence criteria that must be met for main optimizer to converge
criteria 3

# (float) Minimum eigenvalue for applying steepest descent correction in the MainOptimizer
eig_lowerbound 0.01

# (float) Step size for finite difference derivatives in many functions (get_(G/H) in fitsim, FDCheckG)
finite_difference_h 0.001

# (float) Factor for multiplicative penalty function in objective function
penalty_additive 1.0

trust0 0.25
mintrust 0.05
error_tolerance 1.0
adaptive_factor 0.2
adaptive_damping 1.0
normalize_weights no
print_hessian

# Charge constraints are taken care of using "evals".
constrain_charge false

priors
   vdW/Atom/epsilon :  0.1
   vdW/Atom/rmin_half :  1.0
/priors

$end
$target
name phys-prop
type Evaluator_SMIRNOFF
weight 1.0
evaluator_input options.json
$end\n"""
    optin = str(outdir / "optimize.in")
    with open(optin, "w") as f:
        f.write(OPTIN)
    print(f"Wrote {optin}")

def write_server_config(outdir, port=8005):
    config = {"backend_config": {"type": "dask-local",
                                "number_of_workers": 4,
                                "resources_per_worker": {"n_processes": 10,
                                                         "n_gpus": 1,},
                                },
            "port": port,
            "working_directory": "evaluator_working-data",
            "enable_data_caching": None}

    cfgfile = str(outdir / "server-config.json")
    with open(cfgfile, "w") as f:
        json.dump(config, f)
    print(f"Wrote {cfgfile}")


def write_prop_input(outdir, training_set, port=8005):
    path = outdir / "targets/phys-prop"
    path.mkdir(exist_ok=True, parents=True)

    write_training_set(path, training_set)
    write_options(path, port=port)


def df_to_resp2_librarycharge(df_, delta=0.6, method="resp2"):
    df_ = df_[df_.Delta.round(2) == delta]
    df_ = df_[df_.Weight == 1]
    df_ = df_[df_.Grid == method]
    df_ = df_[df_.Method == METHOD_FULL[method]]
    assert len(df_) == df_["Atom number"].values.max()

    df_ = df_.sort_values("Atom number", inplace=False)
    charges = [x * unit.elementary_charge for x in df_.Charge.values]
    return {"smirks": df_.smirks.values[0], "charge": charges}


def df_to_am1_librarycharge(df_,):
    df_ = df_[df_.Orientation == 1]
    df_ = df_[df_.Conformer == 1]
    df_ = df_[df_.Method == "OpenEye"]
    assert len(df_) == df_["Atom number"].values.max()

    df_ = df_.sort_values("Atom number", inplace=False)
    charges = [x * unit.elementary_charge for x in df_.Charge.values]
    return {"smirks": df_.smirks.values[0], "charge": charges}


def write_forcefield(outdir, training_set, charge_dataframes, delta=None, method="resp2"):
    ffdir = outdir / "forcefield"
    ffdir.mkdir(exist_ok=True)

    ff = ForceField("1.3.0.offxml")
    # add librarycharges
    lc = ff.get_parameter_handler("LibraryCharges")
    if delta is not None:
        for df_ in charge_dataframes:
            lc.add_parameter(df_to_resp2_librarycharge(df_, delta=delta, method=method))
    else:
        for df_ in charge_dataframes:
            lc.add_parameter(df_to_am1_librarycharge(df_))

    # label VDW
    vdw = ff.get_parameter_handler("vdW")
    offmols = [Molecule.from_smiles(x) for x in training_set]
    ongoing_parameters = None
    for offmol in offmols:
        ongoing_parameters = match_parameters(vdw, offmol,
                                              ongoing_parameters=ongoing_parameters)
    for param in ongoing_parameters:
        param.add_cosmetic_attribute("parameterize", "epsilon, rmin_half")
    ff_file = str(ffdir / "force-field.offxml")
    ff.to_file(ff_file)
    print(f"Wrote {ff_file}")
    return ff, ongoing_parameters
    


def match_parameters(vdw_handler, molecule, ongoing_parameters=None):
    if ongoing_parameters is None:
        ongoing_parameters = []
    for parameter in vdw_handler.parameters:
        if parameter not in ongoing_parameters:
            if len(molecule.chemical_environment_matches(parameter.smirks)):
                ongoing_parameters.append(parameter)
    return ongoing_parameters


def write_opt_json(outdir, ff, parameters, delta=None):
    parameters_to_train = [{"handler_type": "vdW", "smirks": param.smirks, "attribute_name": "epsilon"}
                           for param in parameters]
    parameters_to_train += [{"handler_type": "vdW", "smirks": param.smirks, "attribute_name": "rmin_half"}
                            for param in parameters]
    
    if delta is not None:
        id_ = f"resp2-delta-{delta}".replace(".", "")
        pid_ = "charge-models-resp2"
        name_ = f"RESP2, delta={delta}"
    else:
        id_ = "am1bcc-openeye"
        pid_ = "charge-models-am1bcc"
        name_ = "AM1BCC OpenEye"


    dct = {
        "id":  id_,  # only accepts a-z0-9 and -
        "study_id": pid_,
        "project_id": "charge-models",
        "name": name_,
        "description": "charges",
        "force_field": {"inner_content": ff.to_string()},
        "optimization_id": None,
        "analysis_environments": [
            "Aqueous",
            "Secondary Amine",
            "Carboxylic Acid Secondary Amide",
            # "Alkyl Bromide",
            "Alcohol",
            "Aromaticatic", # ???
            # "Aryl Chloride",
            # "Thiol",
            "Carboxylic Acid Tertiary Amide",
            # "Alkyl Chloride",
            "Carboxylic Acid Ester",
            # "Thiourea",
            "Acetal",
            # "Thioether",
            "Tertiary Amine",
            "Ketone",
            # "Disulfide",
            "Aldehyde",
            "Primary Amine",
            "Heterocycle",
            "Ether",
            "Alkene",
            "Alkane",
            # "Sulfone"
        ],
        "model_version": 0,
        "engine": {
            "type": "ForceBalance",
            "convergence_step_criteria": 0.0001,
            "convergence_objective_criteria": 0.0001,
            "convergence_gradient_criteria": 0.0001,
            "n_criteria": 3,
            "initial_trust_radius": 0.25,
            "minimum_trust_radius": 0.05,
            "priors": {
            "vdW/Atom/epsilon": 0.1,
            "vdW/Atom/rmin_half": 1.0
            }
        },
        "targets": [
            {
            "id": "phys-prop",
            "weight": 1.0,
            "model_version": 0,
            "data_set_ids": [
                "charge-model-resp2"
            ],
            "denominators": {
                "SolvationFreeEnergy": "1.6 kJ / mol",
            },
            "allow_direct_simulation": True,
            "n_molecules": None,
            "allow_reweighting": False,
            "n_effective_samples": None
            }
        ],
        "max_iterations": 15,
        "parameters_to_train": parameters_to_train,
    }
    jsonfile = str(outdir / "optimization.json")
    with open(jsonfile, "w") as f:
        json.dump(dct, f)
    print(f"Wrote to {jsonfile}")



def write_input(given_training_set, delta=None, outname="05_vdw", port=8005, method="resp2"):
    if delta is not None:
        subdir = f"{method}-d{delta}"
    else:
        subdir = "am1bcc-openeye"
    outdir = pathlib.Path(outname) / subdir
    outdir.mkdir(exist_ok=True, parents=True)

    dfs = []
    found_training_set = []
    for smi in given_training_set:
        try:
            df_ = pd.read_csv(f"../06_resp/08_results/{smi}/05_calculated_charges.csv")
        except:
            pass
        else:
            found_training_set.append(smi)
            dfs.append(df_)
    found_training_set = sorted(set(found_training_set))

    ff, parameters = write_forcefield(outdir, found_training_set, dfs, delta=delta, method=method)
    write_prop_input(outdir, found_training_set, port=port)
    write_opt_in(outdir)
    write_server_config(outdir, port=port)
    write_opt_json(outdir, ff, parameters, delta=delta)




if __name__ == "__main__":
    args = parser.parse_args()
    
    TRAINING_SET = ["c1ccccc1", "C1CCCCC1", "CCCC", "CCCCCCCCC", "Nc1ccccc1",
                    "CCCCO", "CCCCCC(=O)OC", "O=C(O)c1ccccc1F", "CCN", "CCCCCC(=O)O",
                    "CC(F)F", "Fc1ccccc1", "CCCCOC(C)=O", "Cc1ccc(N)cc1", "CNC", "CC#N",
                    "N#CCC(=O)O", "C#CC", "O", "CCCCc1ccccc1", 'CCN(CC)CC',
                    "N", "CO", "COC", "CCCCCCCCO"]
    write_input(TRAINING_SET, delta=args.delta, port=args.port, method=args.method)

